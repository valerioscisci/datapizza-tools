# Thought Process

- Configurazione iniziale del progetto: creati agenti `datapizza-tools-*` indicando le regole di coding, stili e best practice sia per il fe che per il be
- Aggiornato `CLAUDE.md` con le istruzioni da eseguire ad ogni prompt, commit e per migliorare la gestione del contesto
- Aggiunte istruzioni post-prompt in `CLAUDE.md`: aggiornamento automatico di README.md, THOUGHT_PROCESS.md e agenti dopo ogni prompt completato
- **Visione del progetto**: il mercato del lavoro tech nei prossimi 6-12 mesi sara' stravolto dall'introduzione dei workflow agentici. Si stima che il 60-70% dei lavori digitali saranno impattati. Datapizza deve posizionarsi come punto di riferimento per aiutare gli sviluppatori a navigare questo cambiamento, acquisire nuove competenze e trovare nuovi ruoli
- **Scelte tecniche**: SQLite locale per comodita' e zero costi di hosting nella fase iniziale. FastAPI per lo sviluppo rapido e la possibilita' di deploy su AWS o Vercel (versione Python scelta per compatibilita' con altri progetti esistenti). Next.js con App Router come standard per tutti i nuovi progetti
- **Funzionalita' core pianificate**: (1) replicare e migliorare la job board esistente di Datapizza, (2) profili candidato con tech stack, notifiche giornaliere su corsi AI e progetti di reskilling (newsletter o bot Telegram), (3) "Craft Your Developer" - prodotto B2B a pagamento dove le aziende possono progettare percorsi formativi per candidati specifici e assumerli dopo il reskilling
- **Flusso "Craft Your Developer"**: le aziende navigano i profili dei candidati in cerca di lavoro, selezionano un candidato, progettano un training program personalizzato con corsi e competenze AI necessarie, e poi lo assumono. Questo flusso sara' probabilmente a pagamento per l'azienda
- **Ralph Loop**: deciso di usare il ralph-loop per migliorare lo sviluppo di task lunghi e la gestione del contesto — permette di iterare sullo stesso prompt vedendo il lavoro precedente nei file e nella git history
- **Agenti specializzati**: deciso di usare un set di agenti specializzati (debugger, feature-builder, code-reviewer per BE e FE) per risparmiare context window e essere molto specifici nei piccoli task assegnati
- **Pro Workflow plugin**: deciso di usare il plugin Pro Workflow per non dover ripetere ogni volta le correzioni alle allucinazioni dell'LLM e ai problemi derivanti dal context rot — le correzioni vengono salvate in un database SQLite e applicate automaticamente nelle sessioni successive
- **Design system Datapizza**: estratta la palette colori completa dal sito datapizza.tech — colore primario azure-600 (#1b64f5), font heading Oddval SemiBold, body Poppins, tema solo light. Aggiornati tutti e 3 gli agenti FE (feature-builder, code-reviewer, debugger) con la palette completa, i token semantici, le regole di layout e tipografia
- **SQLite come database**: aggiornati tutti e 3 gli agenti BE per usare SQLite invece di PostgreSQL. Rimossi riferimenti a JSONB, ARRAY, UUID PostgreSQL e sostituiti con pattern compatibili SQLite (TEXT per JSON, String(36) per UUID). Scelta fatta per comodita' e zero costi nella fase iniziale
- **Scaffolding completato**: creato monorepo con pnpm workspaces + Turborepo. FE: Next.js 16.0.11, React 19, Tailwind v4, next-intl con solo locale italiano. BE: FastAPI + SQLAlchemy + SQLite con 10 job finti nel seed. Porte: FE 3003, BE 8003
- **Homepage replicata**: ispirata a datapizza.tech/it con hero section, stats (150+ offerte, 100+ aziende, 50k+ developer), sezione servizi (Craft Your Developer, Mercato del Lavoro, AI Reskilling coming soon), community social stats, CTA finale
- **Pagina Craft Your Developer**: creata landing page B2B completa con: hero, sezione problema del recruiting tech, 4 benefit (formazione mirata, costi ridotti, qualita' garantita, time-to-hire ridotto), 4 step del processo (esplora profili, progetta percorso, formazione guidata, assumi), confronto hiring tradizionale vs CYD, CTA finale
- **Mercato del Lavoro**: pagina jobs con filtri per work_mode (remoto/ibrido/in sede), card con titolo, azienda, location, badge work_mode, salary range, tags tech, descrizione, paginazione. Dati dal BE via fetch API
- **Traduzioni solo italiano**: configurato next-intl con `locales: ['it']`, tutti i testi in `messages/it.json`. Aggiornati agenti FE con questa informazione
- **Monorepo + Turborepo**: deciso di procedere con un approccio monorepo perche' e' lo standard de facto per progetti grandi al momento. Turborepo e' stato scelto perche' quando si builda con Vercel aiuta ad automatizzare il workflow di CD/CI e riduce le build non necessarie
- **Cleanup e code review completa**: eseguita una pulizia completa di tutte le pagine. Rimossa la newsletter dal footer. Aggiunti link reali (termini, privacy, cookie da jobs.datapizza.tech). Corretti tutti i link social (Spotify URL fixato). Aggiunto cursor-pointer su tutti gli elementi interattivi come da standard
- **Jobs Market migliorato**: redesign completo delle card con emoji badge colorati (salario giallo, esperienza azure, work_mode verde, location neutro, welfare rosso), tech tags con priorita' verde, layout 2 colonne, dialog dettaglio job con chiusura su Escape e click esterno
- **Arricchimento dati job**: aggiunti campi experience_years, smart_working, welfare, language al modello DB, schema Pydantic e API. Seed aggiornato con dati realistici per tutti i 10 job
- **Code review FE+BE**: eseguite code review complete con agenti specializzati. Fixati: API URL hardcoded -> env variable, error handling API response, accessibilita' dialog (role="dialog", aria-modal, aria-labelledby), keyboard accessibility su JobCard (tabIndex, role="button", onKeyDown), cursor-pointer mancante su hamburger menu, bottone Candidati collegato ad apply_url, bottone Contattaci CYD collegato a datapizza.tech
- **Autenticazione utente**: implementato sistema auth completo con JWT + bcrypt. Modello User con campi profilo (skills, experience, location, availability_status, reskilling_status, adopted_by_company) pensato per supportare sia il flusso candidato che il futuro flusso CYD B2B. Token JWT con scadenza 24h, secret configurabile via env JWT_SECRET
- **Modello Application**: creato sistema candidature con UniqueConstraint su (user_id, job_id) per prevenire duplicati. Status a 4 valori (proposta/da_completare/attiva/archiviata) con status_detail per info aggiuntive e campi recruiter per tracciare il contatto aziendale
- **Pagine auth FE**: login e signup con form semplici, validazione client-side (password match, lunghezza minima), redirect automatico a /it/jobs dopo successo. AuthContext con React Context API, token in localStorage, validazione on mount via GET /auth/me
- **Navbar aggiornata**: aggiunta sezione auth (desktop: avatar iniziale + link candidature + bottone esci; mobile: stessa logica nel menu hamburger). "Accedi" e "Registrati" quando non loggato. "Le mie candidature" nel dropdown Talents quando loggato
- **Pagina candidature**: replicata UI simile a jobs.datapizza.tech/applications con hero, 4 tab di stato con badge conteggio, card candidatura con info job (salary, experience, work_mode), tech tags, dettagli recruiter e data. Empty state per tab vuoti
- **Bottone Candidati nel job dialog**: integrato con auth — se loggato fa POST /applications, se non loggato redirect a login. Gestione stati success/duplicate/loading. Se il job ha apply_url usa il link esterno come fallback
- **Seed ampliato**: 10 profili developer italiani realistici (nomi, ruoli, skill, citta' diverse) + 6 candidature di esempio distribuite su diversi status. Password hash per tutti "password123" per dev
- **Code review iterativa con Ralph Loop**: eseguiti 2 round completi di code review BE+FE con agenti specializzati + 17 test Playwright E2E. Fixati tutti i BLOCKER e CRITICAL (JWT secret env check, N+1 query, email validation, token expiry check client-side, typed API responses). Secondo round di review ha trovato e fixato: .env JWT_SECRET naming mismatch, get_application JOIN, safe_parse_json_list type validation, errori hardcoded in login/signup, useCallback su login/signup/logout, body scroll lock nel dialog, shared utility per formatSalary/formatDate/workModeLabel, i18n per stringhe nel dialog e paginazione
- **Deduplicazione utility**: estratte funzioni condivise in moduli dedicati sia BE (api/utils.py con safe_parse_json_list) che FE (lib/job-utils.ts con formatSalary, formatDate, workModeLabel). Eliminata duplicazione tra jobs.py, applications.py, auth.py lato BE e tra jobs/page.tsx e candidature/page.tsx lato FE
- **Migrazione a NextAuth v5**: rimosso il sistema auth custom (AuthContext.tsx con JWT in localStorage, client-side token expiry check) e sostituito con next-auth@5.0.0-beta.30. Credentials provider che chiama il backend POST /auth/login + GET /auth/me per ottenere token e profilo utente. Session in httpOnly cookie (piu' sicuro di localStorage). Backend FastAPI rimasto invariato — NextAuth lo wrappa lato FE. Creati: auth.ts (config NextAuth), use-auth.ts (hook custom), route handler [...nextauth], type declarations, Providers.tsx (SessionProvider wrapper). Login usa signIn('credentials'), signup usa flusso a due step (POST signup diretto + signIn per creare sessione). Aggiornate tutte le pagine (login, signup, navbar, candidature, jobs) per usare il nuovo hook useAuth da lib/auth/use-auth
- **Backend News e Corsi**: aggiunti modelli News e Course in models.py seguendo esattamente i pattern esistenti (String(36) UUID, tags_json TEXT, is_active Integer, timestamps UTC). Creati schema Pydantic (NewsResponse, CourseResponse con tags: list[str] tramite safe_parse_json_list) e route FastAPI (GET /news con filtro category AI/tech/careers, GET /news/{id} con 404; GET /courses con filtri category e level, GET /courses/{id} con 404). Ordinamento: news per published_at desc, corsi per created_at desc. Seed con 10 news realistiche (temi AI/tech/careers da HN e TLDR) e 10 corsi realistici (Coursera/Udemy con istruttori, rating, studenti). Route registrate in main.py su /api/v1. Tutti gli endpoint testati e funzionanti
- **Pagine FE News e Corsi**: create le pagine news/page.tsx e courses/page.tsx seguendo esattamente il pattern della pagina jobs (hero, filtri per categoria, griglia 2 colonne di card, dialog dettaglio, paginazione, escape per chiudere). News: filtri all/AI/tech/careers, card con icona Newspaper, badge colorato per categoria (AI=azure, tech=pastelgreen, careers=yellow), tags, summary, data pubblicazione con icona Calendar. Corsi: filtri all/AI/ML/frontend/backend/devops, card con icona GraduationCap, badge livello colorato (beginner=verde, intermediate=azure, advanced=rosso), durata, prezzo, rating con stella, tags. Dialog per entrambi con scroll lock, chiusura su Escape e click esterno, bottone CTA esterno ("Leggi l'articolo" / "Vai al Corso"). Aggiornata Navbar con link "News Tech" e "Corsi di Formazione" nel dropdown Talenti (desktop e mobile). Aggiunte tutte le traduzioni i18n in it.json. Riutilizzato formatDate da job-utils.ts. TypeScript check passato senza errori
- **Code review e fix completati**: eseguite code review BE+FE con agenti specializzati. BE: aggiunti indici composite su News (is_active+published_at, category) e Course (is_active+created_at, category, level) per query performance; fixato session leak in seed con try/finally; estratti helper \_to_news_response e \_to_course_response per eliminare duplicazione. FE: estratto TechTag in componente condiviso @/components/ui/TechTag.tsx (eliminata duplicazione tripla tra jobs, news, courses); spostato handler Escape dentro i dialog component invece che a livello pagina; aggiunto aria-pressed su filtri, aria-live="polite" su contenuto dinamico, aria-hidden su icone decorative Star. Rimosso import useRef inutilizzato da jobs/page.tsx
- **Footer aggiornato**: aggiunti link "News Tech" e "Corsi di Formazione" nella sezione Pagine del footer, allineando la navigazione footer con quella della navbar
- **GitHub Action per fetch notturno di contenuti**: creata una GitHub Action disabilitata (solo workflow_dispatch, cron commentato per le 01:00 AM UTC) che dimostra come popolare automaticamente il database con news e corsi ogni notte. Scelta architetturale chiave: invece di scrivere un classico scraper Python (fragile, si rompe al minimo cambiamento della struttura HTML), si usa **Claude Code come agente** (`npx @anthropic-ai/claude-code --print`), lo stesso pattern usato nel progetto next-monorepo per il daily changelog. L'agente legge le istruzioni da `.claude/agents/datapizza-tools-content-fetcher.md`, fetcha contenuti da 4 fonti (HN API, TLDR Tech, Coursera, Udemy) e li inserisce nel DB usando lo script CLI `apps/api/api/scrapers/insert_content.py`. Lo script CLI riceve JSON da stdin, deduplicata per source_url/url e title+source/provider, e inserisce usando gli stessi modelli SQLAlchemy. Testato localmente: inserimento, deduplicazione e cleanup funzionano correttamente
